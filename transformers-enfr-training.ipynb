{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac82b0c8",
   "metadata": {
    "papermill": {
     "duration": 0.013043,
     "end_time": "2023-10-05T21:31:37.584547",
     "exception": false,
     "start_time": "2023-10-05T21:31:37.571504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# English to French translation with transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304f747",
   "metadata": {
    "papermill": {
     "duration": 0.010459,
     "end_time": "2023-10-05T21:31:37.606919",
     "exception": false,
     "start_time": "2023-10-05T21:31:37.596460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The aim of this notebook is to train an English to French translation system using the transformer encoder-decoder architecture introduced in the paper *Attention is all you need*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2666bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:31:37.630125Z",
     "iopub.status.busy": "2023-10-05T21:31:37.629336Z",
     "iopub.status.idle": "2023-10-05T21:31:42.550729Z",
     "shell.execute_reply": "2023-10-05T21:31:42.549785Z"
    },
    "papermill": {
     "duration": 4.935478,
     "end_time": "2023-10-05T21:31:42.553094",
     "exception": false,
     "start_time": "2023-10-05T21:31:37.617616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cfcfe",
   "metadata": {
    "papermill": {
     "duration": 0.005987,
     "end_time": "2023-10-05T21:31:42.565738",
     "exception": false,
     "start_time": "2023-10-05T21:31:42.559751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7323ed90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:31:42.579761Z",
     "iopub.status.busy": "2023-10-05T21:31:42.579274Z",
     "iopub.status.idle": "2023-10-05T21:31:42.584003Z",
     "shell.execute_reply": "2023-10-05T21:31:42.583043Z"
    },
    "papermill": {
     "duration": 0.013882,
     "end_time": "2023-10-05T21:31:42.585692",
     "exception": false,
     "start_time": "2023-10-05T21:31:42.571810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_in = 7 # Length of input sentences\n",
    "N_out = 8 # Length of output sentences\n",
    "emb_size = 300 # Size of embedded vectors\n",
    "n_layers = 6 # Number of layers for encoder and decoder stacks\n",
    "nhead = 6 # Number of heads in multihead attention layers\n",
    "dim_feedforward = 1024 # Number of hidden neurons in positionwise-FCNN \n",
    "dim_out_hidden = 1024 # Number of hidden neurons in output FCNN\n",
    "dropout = 0.1 # Dropout value\n",
    "num_fr_words = 2000 # Length of French word list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a76f9",
   "metadata": {
    "papermill": {
     "duration": 0.006866,
     "end_time": "2023-10-05T21:31:42.598736",
     "exception": false,
     "start_time": "2023-10-05T21:31:42.591870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model is split into an encoding step and a decoding step. \n",
    "\n",
    "Encoding step:\n",
    "- **Raw input**: English sentence consisting of a sequence of `N_in` strings (words and other tokens such as `<eos>`and `<pad>`). \n",
    "- **Embedding**: FastText converts each sentence into a sequence of `N_in` float vectors of size `emb_size`\n",
    "- **Encoder stack**: Given the sequence of `N_in` embedded vectors, the encoder stack outputs a sequence of `N_in` vectors of the same size `emb_size`, intended to be a latent representation of the input sentence. The encoder stack consists in first adding a positional encoding signal to the input, then applying `n_layers` \"Transformer encoder\" layers. Each transformer encoder layer consists of two sub-layers: a multi-head self-attention layer (with `nhead` heads) and a positionwise-FCNN (single hidden layer with `dim_feedforward` neurons), with residual connections and layer-normalisation applied after each sub-layer.\n",
    "\n",
    "For the decoding step of the model we need the following element:\n",
    "- **French word-list**: A list `fr_wordlst` of French words and punctuation from which the model will construct its output. The word-list also includes a end-of-sentence token `<eos>`.\n",
    "\n",
    "The decoder stack starts with a sequence `output` with only one element, the beginning of sentence token `<bos>`. The model then iteratively generates the next word/token of the ouput sentence and appends it to the `output` sequence until:\n",
    "- **Termination condition**: Either the end of sentence token `<eos>` is generated or the sequence output reaches a length `N_out` (including the `<bos>` token). \n",
    "\n",
    "The generation of the next word is performed as follows:\n",
    "- **Embedding**: FastText converts each word/token of the current instance of the sequence `translation`into a vector of size `emb_size`\n",
    "- **Decoder stack**: Given the above sequence of vectors, the decoder stack outputs a sequence of vectors of the same size. The decoder stack consists in `n_layers` \"Transformer decoder\" layers. Each transformer decoder layer consists of three sub-layers: a multi-head self-attention layer applied to the embedding of the sequence `translation`, a multi-head \"encoder-decoder\" attention layer (the queries and values come from the output of the encoder stack and the queries come from the previous self-attention layer) and a positionwise-FCNN. A residual connection and layer normalisation is applied after each sub-layer. The number of heads in both multi-head attention layers is `nhead` and the positionwise-FCNN has a single hidden layer with `dim_feedforward` neurons.\n",
    "- **Output layer**: An FCNN with a single hidden layer (`dim_out_hidden` neurons), applied to the final vector of the decoder output, followed by a softmax function, gives a probability distribution of the French word-list `fr_wordlst`. The next word with the highest probability is appended onto `translation`.\n",
    "\n",
    "Training of the model shall be performed as follows:\n",
    "- **Training dataset**: The input variables are the English sentence and the first $N$ words/tokens of the French translation, where $N$ varies from 1 (just the `<bos>` token) to the entire length of the translation sequence. The target variable is the next word of the translation or the `<eos>` token if the entire translation is given as input.\n",
    "- **Loss function**: Cross-entropy loss function is used to compare the probability distribution over `fr_wordlst` outputted by the model with a one-hot vector representing the target variable. If the target variable is not in `fr_wordlst`, then we set the loss to zero.\n",
    "- **Regularisation**: Dropout with value `dropout`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cfd293",
   "metadata": {
    "papermill": {
     "duration": 0.005836,
     "end_time": "2023-10-05T21:31:42.610913",
     "exception": false,
     "start_time": "2023-10-05T21:31:42.605077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Embedding layers\n",
    "\n",
    "First, we create two functions which take in a sentence (English or French resp.) and outputs a 2d PyTorch tensor representing a sequence of vectors. We use fastText, which provides vectors for words and punctuation.\n",
    "* Unknown token `<unk>` is represented by the zero vector.\n",
    "* Beginning of sentence token `<bos>`  is represented by `2*torch.ones(emb_size)`.\n",
    "* Padding token `<pad>` is represented by `- 2*torch.ones(emb_size)`.\n",
    "\n",
    "**To do** `<eos>` token not `<pad>` token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3703fa48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:31:42.624892Z",
     "iopub.status.busy": "2023-10-05T21:31:42.624107Z",
     "iopub.status.idle": "2023-10-05T21:32:44.669565Z",
     "shell.execute_reply": "2023-10-05T21:32:44.668518Z"
    },
    "papermill": {
     "duration": 62.054786,
     "end_time": "2023-10-05T21:32:44.671880",
     "exception": false,
     "start_time": "2023-10-05T21:31:42.617094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:03<00:00, 8421.79it/s]\n",
      "100%|██████████| 30000/30000 [00:04<00:00, 6973.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# French embedding\n",
    "vocab_fr = torchtext.vocab.Vectors('/kaggle/input/fasttext-french-2b-300d/cc.fr.300.vec',max_vectors = 30000)\n",
    "# English embedding\n",
    "vocab_en = torchtext.vocab.Vectors('/kaggle/input/fasttext-wikinews/wiki-news-300d-1M.vec',max_vectors = 30000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7261bf41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:44.694781Z",
     "iopub.status.busy": "2023-10-05T21:32:44.694209Z",
     "iopub.status.idle": "2023-10-05T21:32:44.757419Z",
     "shell.execute_reply": "2023-10-05T21:32:44.756346Z"
    },
    "papermill": {
     "duration": 0.077155,
     "end_time": "2023-10-05T21:32:44.759522",
     "exception": false,
     "start_time": "2023-10-05T21:32:44.682367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0797, -0.0294,  0.0033,  ...,  0.1372,  0.0669, -0.0084],\n",
      "        [-0.1179,  0.0636, -0.0078,  ...,  0.0994,  0.0352, -0.0196],\n",
      "        [ 0.0752,  0.1227,  0.1374,  ...,  0.1154, -0.0208, -0.0434],\n",
      "        [ 0.0004,  0.0032, -0.0204,  ...,  0.2070,  0.0689, -0.0467]])\n"
     ]
    }
   ],
   "source": [
    "# example 1\n",
    "sent_en = 'The dogs ate .'\n",
    "print(vocab_en.get_vecs_by_tokens(sent_en.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3679bfaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:44.783601Z",
     "iopub.status.busy": "2023-10-05T21:32:44.782611Z",
     "iopub.status.idle": "2023-10-05T21:32:44.789550Z",
     "shell.execute_reply": "2023-10-05T21:32:44.788463Z"
    },
    "papermill": {
     "duration": 0.020895,
     "end_time": "2023-10-05T21:32:44.791494",
     "exception": false,
     "start_time": "2023-10-05T21:32:44.770599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0594,  0.0330, -0.0503,  ...,  0.1932, -0.0023,  0.0341],\n",
      "        [ 0.0084,  0.0216,  0.0323,  ...,  0.0561,  0.0040,  0.1386],\n",
      "        [ 0.0092,  0.0073, -0.2033,  ..., -0.1730,  0.0966,  0.0489],\n",
      "        [ 0.1356, -0.0000, -0.0007,  ...,  0.0340,  0.0039,  0.0621],\n",
      "        [ 0.1828, -0.1425, -0.1679,  ..., -0.3886, -0.1527,  0.0675]])\n"
     ]
    }
   ],
   "source": [
    "# example 2\n",
    "sent_fr = \"Les chiens a mange ?\"\n",
    "print(vocab_fr.get_vecs_by_tokens(sent_fr.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469ff598",
   "metadata": {
    "papermill": {
     "duration": 0.010865,
     "end_time": "2023-10-05T21:32:44.813297",
     "exception": false,
     "start_time": "2023-10-05T21:32:44.802432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Words such as \"we're\" and \"c'est\" are not recognised by the word embedding algorithms. \n",
    "\n",
    "This is why we treat them as multiple tokens, i.e. [we,',re] and [c,',est] resp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30e5ecf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:44.836673Z",
     "iopub.status.busy": "2023-10-05T21:32:44.835810Z",
     "iopub.status.idle": "2023-10-05T21:32:44.849072Z",
     "shell.execute_reply": "2023-10-05T21:32:44.847902Z"
    },
    "papermill": {
     "duration": 0.02652,
     "end_time": "2023-10-05T21:32:44.850887",
     "exception": false,
     "start_time": "2023-10-05T21:32:44.824367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(2.1135) tensor(1.4133) tensor(1.9807)\n",
      "tensor(0.) tensor(0.5633) tensor(0.6729) tensor(2.5800) tensor(3.0775)\n"
     ]
    }
   ],
   "source": [
    "# example 3a\n",
    "print(torch.norm(vocab_en[\"we're\"]),torch.norm(vocab_en[\"we\"]),torch.norm(vocab_en[\"'\"]),torch.norm(vocab_en[\"re\"]))\n",
    "# example 3b\n",
    "print(torch.norm(vocab_fr[\"puisqu'il\"]),torch.norm(vocab_fr[\"puisqu'\"]), torch.norm(vocab_fr[\"puisqu\"]), torch.norm(vocab_fr[\"'\"]), torch.norm(vocab_fr[\"il\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837e6d6c",
   "metadata": {
    "papermill": {
     "duration": 0.009609,
     "end_time": "2023-10-05T21:32:44.870679",
     "exception": false,
     "start_time": "2023-10-05T21:32:44.861070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### French word-list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e82ecf",
   "metadata": {
    "papermill": {
     "duration": 0.009594,
     "end_time": "2023-10-05T21:32:44.889803",
     "exception": false,
     "start_time": "2023-10-05T21:32:44.880209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Importing a previously prepared list of French words as a Pandas Series and truncating to `num_fr_words` words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca753b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:44.910260Z",
     "iopub.status.busy": "2023-10-05T21:32:44.909727Z",
     "iopub.status.idle": "2023-10-05T21:32:44.936128Z",
     "shell.execute_reply": "2023-10-05T21:32:44.935288Z"
    },
    "papermill": {
     "duration": 0.038523,
     "end_time": "2023-10-05T21:32:44.938046",
     "exception": false,
     "start_time": "2023-10-05T21:32:44.899523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr_wordlst = pd.read_csv(\"/kaggle/input/list-of-french-words/french_counter.txt\").iloc[:num_fr_words,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfefa50d",
   "metadata": {
    "papermill": {
     "duration": 0.009777,
     "end_time": "2023-10-05T21:32:44.957687",
     "exception": false,
     "start_time": "2023-10-05T21:32:44.947910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Encoder and decoder stacks\n",
    "\n",
    "The encoder and decoder stacks  are conveniently available as a pre-implemented module in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53305c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:44.978497Z",
     "iopub.status.busy": "2023-10-05T21:32:44.977936Z",
     "iopub.status.idle": "2023-10-05T21:32:45.381612Z",
     "shell.execute_reply": "2023-10-05T21:32:45.380206Z"
    },
    "papermill": {
     "duration": 0.416504,
     "end_time": "2023-10-05T21:32:45.383831",
     "exception": false,
     "start_time": "2023-10-05T21:32:44.967327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 300])\n",
      "torch.Size([8, 300])\n",
      "torch.Size([10, 4, 300])\n"
     ]
    }
   ],
   "source": [
    "enc_dec = torch.nn.Transformer(d_model=emb_size, nhead=nhead, num_encoder_layers=n_layers, num_decoder_layers=n_layers,\n",
    "                               dim_feedforward = dim_feedforward, dropout=dropout, batch_first=True)\n",
    "# Examples: unbatched data\n",
    "src = torch.rand((N_in,emb_size)) # Input into encoder\n",
    "tgt = torch.rand((1,emb_size)) # Input into decoder\n",
    "print(enc_dec(src,tgt).shape)\n",
    "src = torch.rand((N_in,emb_size))\n",
    "tgt = torch.rand((8,emb_size))\n",
    "print(enc_dec(src,tgt).shape)\n",
    "# Examples: unbatched data\n",
    "nbatch = 10\n",
    "src = torch.rand((nbatch,N_in,emb_size)) \n",
    "tgt = torch.rand((nbatch,4,emb_size))\n",
    "print(enc_dec(src,tgt).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cd7618",
   "metadata": {
    "papermill": {
     "duration": 0.00996,
     "end_time": "2023-10-05T21:32:45.404829",
     "exception": false,
     "start_time": "2023-10-05T21:32:45.394869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Construction of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220af689",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:45.427032Z",
     "iopub.status.busy": "2023-10-05T21:32:45.426690Z",
     "iopub.status.idle": "2023-10-05T21:32:45.441569Z",
     "shell.execute_reply": "2023-10-05T21:32:45.440638Z"
    },
    "papermill": {
     "duration": 0.028379,
     "end_time": "2023-10-05T21:32:45.443454",
     "exception": false,
     "start_time": "2023-10-05T21:32:45.415075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TranslationSystem(nn.Module):\n",
    "    \n",
    "    def __init__(self, fr_wordlst, # List of French words \n",
    "                       N_in = 7, # Length of input sentences\n",
    "                       N_out = 8, # Length of output sentences\n",
    "                       emb_size = 300, # Size of embedded vectors\n",
    "                       n_layers = 6, # Number of layers for encoder and decoder stacks\n",
    "                       nhead = 6, # Number of heads in multihead attention layers\n",
    "                       dim_feedforward = 1024, # Number of hidden neurons in positionwise-FCNN \n",
    "                       dim_out_hidden = 1024, # Number of hidden neurons in output FCNN\n",
    "                       dropout = 0.1 # Dropout value\n",
    "                ):\n",
    "        super(TranslationSystem,self).__init__()\n",
    "        \n",
    "        self._num_fr_words = len(fr_wordlst)\n",
    "        self._wordlst_full = pd.concat([fr_wordlst, pd.Series(['<eos>'])],ignore_index=True)\n",
    "        self.bos_vec = 2*torch.ones(emb_size)\n",
    "        \n",
    "        self.enc_dec = torch.nn.Transformer(d_model=emb_size, nhead=nhead, num_encoder_layers=n_layers, num_decoder_layers=n_layers,\n",
    "                               dim_feedforward = dim_feedforward, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        self.fc_out1 = nn.Linear(emb_size,dim_out_hidden)\n",
    "        self.fc_out2 = nn.Linear(dim_out_hidden,self._num_fr_words + 1)\n",
    "        \n",
    "    def forward(self,X, Y):\n",
    "        '''\n",
    "        Outputs a logit probability distribution (pre-softmax) over `fr_wordlst` given batch of pre-embedded sentences.\n",
    "        `X`: Input\n",
    "        `Y`: Partial output (including <bos> token)\n",
    "        '''\n",
    "        out_seq = self.enc_dec(X,Y)\n",
    "        a1 = F.relu(self.fc_out1(out_seq[:,-1,:]))\n",
    "        logits = self.fc_out2(a1)\n",
    "        return logits\n",
    "    \n",
    "    @staticmethod\n",
    "    def pre_process(sent):\n",
    "        '''\n",
    "        Pre-processing pipeline from data preparation\n",
    "        '''\n",
    "        sent = sent.lower() # Make data lowercase\n",
    "        sent = sent.replace('.','').replace('!','') # Remove full stops and exclamation marks.\n",
    "        sent = sent.replace('?',' ? ').replace(',',' , ') # Replace \"?\" by \" ? \" and \",\" by \" , \"\n",
    "        sent = sent.replace('-',' - ').replace(\"'\",\" ' \") # Replace \"-\" by \" - \" and \"'\" by \" ' \"\n",
    "        sent = re.sub('\\xa0|\\xad|\\u2009|\\u200b|\\u202f',' ', sent) # Replace unbreakable spaces by spaces.\n",
    "        sent = re.sub('   ',' ', sent) # Removing triple spaces\n",
    "        sent = re.sub('  ',' ', sent)  # Removing double spaces\n",
    "        sent = re.sub('^ ','', sent) # remove leading space\n",
    "        sent = re.sub(' $','', sent) # remove trailing space\n",
    "        return sent\n",
    "    \n",
    "    def next_word(self, sent_en, sent_fr, vocab_en = vocab_en, vocab_fr = vocab_fr):\n",
    "        '''\n",
    "        Outputs the next word of the French translation given a single English-French sentence pair\n",
    "        '''\n",
    "        sent_en = self.pre_process(sent_en); sent_fr = self.pre_process(sent_fr)\n",
    "        X_raw = vocab_en.get_vecs_by_tokens(sent_en.split(' '))\n",
    "        pad_seq = - 2*torch.ones(N_in - X_raw.shape[0],emb_size)\n",
    "        X = torch.concat([X_raw, pad_seq],dim=0).reshape(1,N_in,emb_size) # append <pad> vectors\n",
    "        Y_raw = vocab_fr.get_vecs_by_tokens(sent_fr.split(' '))\n",
    "        Y = torch.concat([self.bos_vec.unsqueeze(dim=0),Y_raw],dim=0).unsqueeze(dim=0) # prepend <bos> vector\n",
    "        idx_maxprob = torch.argmax(self.forward(X,Y)).item()\n",
    "        return self._wordlst_full.iloc[idx_maxprob]\n",
    "    \n",
    "    def translate(self, sent_en, vocab_en = vocab_en, vocab_fr = vocab_fr):\n",
    "        '''\n",
    "        Outputs the French translation of a single English sentence\n",
    "        '''\n",
    "        sent_en = self.pre_process(sent_en)\n",
    "        sent_fr = ''\n",
    "        X_raw = vocab_en.get_vecs_by_tokens(sent_en.split(' '))\n",
    "        pad_seq = - 2*torch.ones(N_in - X_raw.shape[0],emb_size)\n",
    "        X = torch.concat([X_raw, pad_seq],dim=0).reshape(1,N_in,emb_size) # append <pad> vectors\n",
    "        Y = self.bos_vec.reshape(1,1,emb_size)\n",
    "        for n in range(N_out):\n",
    "            idx_maxprob = torch.argmax(self.forward(X,Y)).item()\n",
    "            next_word_str = self._wordlst_full.iloc[idx_maxprob]\n",
    "            if next_word_str == '<eos>':\n",
    "                break\n",
    "            sent_fr += ' ' + next_word_str\n",
    "            next_word_vec = vocab_fr[next_word_str]\n",
    "            Y = torch.concat([Y,next_word_vec.reshape(1,1,emb_size)],dim = 1)\n",
    "        sent_fr = sent_fr[1:] # Removes leading space\n",
    "        return sent_fr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c758419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:45.465235Z",
     "iopub.status.busy": "2023-10-05T21:32:45.464473Z",
     "iopub.status.idle": "2023-10-05T21:32:45.686732Z",
     "shell.execute_reply": "2023-10-05T21:32:45.685441Z"
    },
    "papermill": {
     "duration": 0.235215,
     "end_time": "2023-10-05T21:32:45.688689",
     "exception": false,
     "start_time": "2023-10-05T21:32:45.453474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2001])\n"
     ]
    }
   ],
   "source": [
    "# Test forward\n",
    "model = TranslationSystem(fr_wordlst)\n",
    "src = torch.rand((2,N_in,emb_size)) # Input into encoder\n",
    "tgt = torch.rand((2,4,emb_size)) # Input into decoder\n",
    "probs = model(src,tgt)\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca8460a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:45.710211Z",
     "iopub.status.busy": "2023-10-05T21:32:45.709440Z",
     "iopub.status.idle": "2023-10-05T21:32:45.715577Z",
     "shell.execute_reply": "2023-10-05T21:32:45.714511Z"
    },
    "papermill": {
     "duration": 0.01876,
     "end_time": "2023-10-05T21:32:45.717340",
     "exception": false,
     "start_time": "2023-10-05T21:32:45.698580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello , we ' re testing\n"
     ]
    }
   ],
   "source": [
    "# Test pre_process\n",
    "print(TranslationSystem.pre_process(\"Hello, we're  testing \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8005651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:45.739354Z",
     "iopub.status.busy": "2023-10-05T21:32:45.738483Z",
     "iopub.status.idle": "2023-10-05T21:32:45.962402Z",
     "shell.execute_reply": "2023-10-05T21:32:45.961482Z"
    },
    "papermill": {
     "duration": 0.23708,
     "end_time": "2023-10-05T21:32:45.964373",
     "exception": false,
     "start_time": "2023-10-05T21:32:45.727293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sort'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test next_word \n",
    "model = TranslationSystem(fr_wordlst)\n",
    "model.next_word('there is a car', 'il y a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3624e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:45.985812Z",
     "iopub.status.busy": "2023-10-05T21:32:45.985528Z",
     "iopub.status.idle": "2023-10-05T21:32:46.409710Z",
     "shell.execute_reply": "2023-10-05T21:32:46.408725Z"
    },
    "papermill": {
     "duration": 0.437087,
     "end_time": "2023-10-05T21:32:46.411654",
     "exception": false,
     "start_time": "2023-10-05T21:32:45.974567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stylo salon chanter chanter chanter venir pleure court'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test translate\n",
    "model = TranslationSystem(fr_wordlst)\n",
    "model.translate('there is a car')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5443c615",
   "metadata": {
    "papermill": {
     "duration": 0.010082,
     "end_time": "2023-10-05T21:32:46.432387",
     "exception": false,
     "start_time": "2023-10-05T21:32:46.422305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c83cf7c",
   "metadata": {
    "papermill": {
     "duration": 0.009832,
     "end_time": "2023-10-05T21:32:46.452634",
     "exception": false,
     "start_time": "2023-10-05T21:32:46.442802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, we import a previously prepared dataset consisting of English-French sentence pairs (see the notebook \"Transformers-EnFr-DatasetCleaning\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "896567f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:46.474422Z",
     "iopub.status.busy": "2023-10-05T21:32:46.473513Z",
     "iopub.status.idle": "2023-10-05T21:32:46.624451Z",
     "shell.execute_reply": "2023-10-05T21:32:46.623511Z"
    },
    "papermill": {
     "duration": 0.163763,
     "end_time": "2023-10-05T21:32:46.626455",
     "exception": false,
     "start_time": "2023-10-05T21:32:46.462692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>En</th>\n",
       "      <th>Fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>va</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>salut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>cours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who ?</td>\n",
       "      <td>qui ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "      <td>ça alors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53864</th>\n",
       "      <td>his helplessness appeals to her motherly sympathy</td>\n",
       "      <td>son impuissance éveille sa compassion maternelle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53865</th>\n",
       "      <td>the conflict began over a simple misunderstanding</td>\n",
       "      <td>le conflit commença sur un simple malentendu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53866</th>\n",
       "      <td>the students divided themselves into three groups</td>\n",
       "      <td>les étudiants se divisèrent en trois groupes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53867</th>\n",
       "      <td>draw two concentric circles of differing diame...</td>\n",
       "      <td>tracez deux cercles concentriques de diamètres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53868</th>\n",
       "      <td>an undercover operative infiltrated the organi...</td>\n",
       "      <td>un agent secret infiltra l ' organisation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53869 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      En  \\\n",
       "0                                                     go   \n",
       "1                                                     hi   \n",
       "2                                                    run   \n",
       "3                                                  who ?   \n",
       "4                                                    wow   \n",
       "...                                                  ...   \n",
       "53864  his helplessness appeals to her motherly sympathy   \n",
       "53865  the conflict began over a simple misunderstanding   \n",
       "53866  the students divided themselves into three groups   \n",
       "53867  draw two concentric circles of differing diame...   \n",
       "53868  an undercover operative infiltrated the organi...   \n",
       "\n",
       "                                                      Fr  \n",
       "0                                                     va  \n",
       "1                                                  salut  \n",
       "2                                                  cours  \n",
       "3                                                  qui ?  \n",
       "4                                               ça alors  \n",
       "...                                                  ...  \n",
       "53864   son impuissance éveille sa compassion maternelle  \n",
       "53865       le conflit commença sur un simple malentendu  \n",
       "53866       les étudiants se divisèrent en trois groupes  \n",
       "53867  tracez deux cercles concentriques de diamètres...  \n",
       "53868          un agent secret infiltra l ' organisation  \n",
       "\n",
       "[53869 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_str = pd.read_csv(\"/kaggle/input/enfr-cleaned/EnFr_cleaned.txt\").iloc[:,1:]\n",
    "dataset_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2492cd97",
   "metadata": {
    "papermill": {
     "duration": 0.010099,
     "end_time": "2023-10-05T21:32:46.647048",
     "exception": false,
     "start_time": "2023-10-05T21:32:46.636949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Importing embedded sentences pairs, with appropriate padding and with `<bos>` prepended to the French token sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad47a7e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:46.669837Z",
     "iopub.status.busy": "2023-10-05T21:32:46.668908Z",
     "iopub.status.idle": "2023-10-05T21:32:53.829880Z",
     "shell.execute_reply": "2023-10-05T21:32:53.828827Z"
    },
    "papermill": {
     "duration": 7.174612,
     "end_time": "2023-10-05T21:32:53.832225",
     "exception": false,
     "start_time": "2023-10-05T21:32:46.657613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_en, X_fr  = torch.load('/kaggle/input/tensorised-enfr-sentence-pairs/EnFr_tensors.pt').tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a631d195",
   "metadata": {
    "papermill": {
     "duration": 0.010081,
     "end_time": "2023-10-05T21:32:53.853026",
     "exception": false,
     "start_time": "2023-10-05T21:32:53.842945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creating the target data: the sequence of indices in the French word list corresponding to each French sentence. The target data shall differ between the cases of training models with and without terminations.\n",
    "\n",
    "When training models with termination, the target set is denoted by `Ystop` and shall run over indices `[0,...,2001]` with index 2000 marking padding tokens. We mark unknown words (words not in `fr_wordlst`) the index 2001, which shall act as an \"ignore\" index in this case (datapoints with this target index won't contribute to the cost function).\n",
    "\n",
    "When training models without termination, the target set is denoted by `Ycont` and shall run over indices `[0,...,2000]`, where we mark both padding tokens and unknown with an \"ignore\" index 2000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4599659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:53.875209Z",
     "iopub.status.busy": "2023-10-05T21:32:53.874631Z",
     "iopub.status.idle": "2023-10-05T21:32:53.891278Z",
     "shell.execute_reply": "2023-10-05T21:32:53.890125Z"
    },
    "papermill": {
     "duration": 0.029688,
     "end_time": "2023-10-05T21:32:53.893049",
     "exception": false,
     "start_time": "2023-10-05T21:32:53.863361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0,   36, 2001,   13,   58, 2000, 2000, 2000])\n"
     ]
    }
   ],
   "source": [
    "# Example \n",
    "sentence = 'je suis blahblah une personne'\n",
    "wordlst_full = pd.concat([fr_wordlst, pd.Series(['<eos>','<unk>'])],ignore_index=True)\n",
    "word_to_idx = {v: k for k, v in dict(wordlst_full).items()}\n",
    "seq_short = torch.tensor([word_to_idx.get(word,2001) for word in sentence.split(' ')])\n",
    "seq = torch.concat([seq_short,2000*torch.ones(N_out - len(seq_short), dtype = torch.int64)])\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de42ad38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:32:53.915059Z",
     "iopub.status.busy": "2023-10-05T21:32:53.914546Z",
     "iopub.status.idle": "2023-10-05T21:33:05.293388Z",
     "shell.execute_reply": "2023-10-05T21:33:05.292399Z"
    },
    "papermill": {
     "duration": 11.392047,
     "end_time": "2023-10-05T21:33:05.295516",
     "exception": false,
     "start_time": "2023-10-05T21:32:53.903469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53868/53868 [00:11<00:00, 4740.80it/s]\n"
     ]
    }
   ],
   "source": [
    "wordlst_full = pd.concat([fr_wordlst, pd.Series(['<eos>','<unk>'])],ignore_index=True)\n",
    "word_to_idx = {v: k for k, v in dict(wordlst_full).items()}\n",
    "sentence = dataset_str.Fr.iloc[0]\n",
    "seq_short = torch.tensor([word_to_idx.get(word,2001) for word in sentence.split(' ')])\n",
    "seq = torch.concat([seq_short,2000*torch.ones(N_out - len(seq_short), dtype = torch.int64)])\n",
    "Y = seq.unsqueeze(0)\n",
    "for sentence in tqdm(dataset_str.Fr.iloc[1:]):\n",
    "    seq_short = torch.tensor([word_to_idx.get(word,2001) for word in sentence.split(' ')])\n",
    "    seq = torch.concat([seq_short,2000*torch.ones(N_out - len(seq_short), dtype = torch.int64)])\n",
    "    Y = torch.concat([Y, seq.unsqueeze(0)], dim = 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65af263",
   "metadata": {
    "papermill": {
     "duration": 0.015657,
     "end_time": "2023-10-05T21:33:05.327106",
     "exception": false,
     "start_time": "2023-10-05T21:33:05.311449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Creating a PyTorch dataset structure encompassing the embedded English sentences, embedded French sentences, index sequences for the French sentences and the original index of the sentence pair (for reference back to the non-embedded dataset `dataset_str` after randomised test-train split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9fd77f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:33:05.359471Z",
     "iopub.status.busy": "2023-10-05T21:33:05.358826Z",
     "iopub.status.idle": "2023-10-05T21:33:05.365733Z",
     "shell.execute_reply": "2023-10-05T21:33:05.364842Z"
    },
    "papermill": {
     "duration": 0.024975,
     "end_time": "2023-10-05T21:33:05.367545",
     "exception": false,
     "start_time": "2023-10-05T21:33:05.342570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentencePairs(Dataset):\n",
    "    def __init__(self, X_en, X_fr, Y):\n",
    "        assert X_en.shape[0] ==  X_fr.shape[0] ==  Y.shape[0]\n",
    "        self.X_en = X_en\n",
    "        self.X_fr = X_fr\n",
    "        self.Y = Y\n",
    "        self.original_index = torch.tensor(range(self.Y.shape[0]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_en[index,:,:], self.X_fr[index,:,:], self.Y[index,:], self.original_index[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3348fa5d",
   "metadata": {
    "papermill": {
     "duration": 0.015186,
     "end_time": "2023-10-05T21:33:05.397800",
     "exception": false,
     "start_time": "2023-10-05T21:33:05.382614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Initialising the dataset and performing a test-train split with 80% training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb2bd09f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:33:05.430472Z",
     "iopub.status.busy": "2023-10-05T21:33:05.429613Z",
     "iopub.status.idle": "2023-10-05T21:33:05.455998Z",
     "shell.execute_reply": "2023-10-05T21:33:05.455105Z"
    },
    "papermill": {
     "duration": 0.044931,
     "end_time": "2023-10-05T21:33:05.457929",
     "exception": false,
     "start_time": "2023-10-05T21:33:05.412998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = SentencePairs(X_en, X_fr, Y)\n",
    "trainset, valset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf1682",
   "metadata": {
    "papermill": {
     "duration": 0.01516,
     "end_time": "2023-10-05T21:33:05.488859",
     "exception": false,
     "start_time": "2023-10-05T21:33:05.473699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656d511",
   "metadata": {
    "papermill": {
     "duration": 0.015184,
     "end_time": "2023-10-05T21:33:05.519690",
     "exception": false,
     "start_time": "2023-10-05T21:33:05.504506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Main training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "722fc744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:33:05.550784Z",
     "iopub.status.busy": "2023-10-05T21:33:05.550471Z",
     "iopub.status.idle": "2023-10-05T21:33:05.566584Z",
     "shell.execute_reply": "2023-10-05T21:33:05.565513Z"
    },
    "papermill": {
     "duration": 0.033802,
     "end_time": "2023-10-05T21:33:05.568316",
     "exception": false,
     "start_time": "2023-10-05T21:33:05.534514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def give_cost_0(dataset, model, loss_fn):\n",
    "    'Cost for predicting first word (for evaluation while training)'\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)\n",
    "    cost = 0\n",
    "    for X_en, X_fr, Y, idx in dataloader:\n",
    "        X_en =  X_en.to(device); X_fr =  X_fr.to(device); Y =  Y.to(device)\n",
    "        N = 0 \n",
    "        Xfr_trunc = X_fr[:,:N+1,:] \n",
    "        outputs = model(X_en,Xfr_trunc)\n",
    "        labels = Y[:,N]\n",
    "        loss = loss_fn(outputs,labels) \n",
    "        cost += loss.item()\n",
    "    return cost/len(dataloader)\n",
    "\n",
    "def give_cost_all(dataset, model):\n",
    "    'Costs for predicting all word (for final evaluation)' \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)\n",
    "    ignore_index = 2001\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=ignore_index) \n",
    "    \n",
    "    cost_lst = [0 for N in range(N_out)]\n",
    "    for X_en, X_fr, Y, idx in tqdm(dataloader):\n",
    "        X_en =  X_en.to(device); X_fr =  X_fr.to(device); Y =  Y.to(device)\n",
    "        for N in range(N_out):\n",
    "            Xfr_trunc = X_fr[:,:N+1,:] \n",
    "            outputs = model(X_en,Xfr_trunc)\n",
    "            labels = Y[:,N]\n",
    "            loss = loss_fn(outputs,labels) \n",
    "            if loss.item() > 0:\n",
    "                cost_lst[N] += loss.item()\n",
    "    return [cost/len(dataloader) for cost in cost_lst]\n",
    "\n",
    "\n",
    "def train(model, optimiser, n_epochs, batch_size, train_set, val_set, device, printing):\n",
    "    dataloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "    ignore_index = 2001\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=ignore_index) \n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    cost_hist = {N : [] for N in range(N_out + 1)}\n",
    "    run_train_hist = []\n",
    "\n",
    "    # Initial validation cost\n",
    "    start_val_cost = give_cost_0(val_set, model, loss_fn)\n",
    "    val_hist = [start_val_cost]\n",
    "    print('Initial validation cost: ', start_val_cost)\n",
    "    \n",
    "    best_model = model\n",
    "    best_epoch = (0,start_val_cost)\n",
    "    step = 0\n",
    "    for n in range(n_epochs):\n",
    "        epoch_train_cost = 0\n",
    "        for X_en, X_fr, Y, idx in dataloader:\n",
    "            X_en =  X_en.to(device); X_fr =  X_fr.to(device); Y =  Y.to(device)\n",
    "            \n",
    "            # Generate random value of N according to skewed distribution\n",
    "            N = np.random.randint(N_out - 1)\n",
    "            # Take first N + 1 tokens in French sentences (including <bos>) \n",
    "            Xfr_trunc = X_fr[:,:N+1,:]\n",
    "            \n",
    "            # Training step\n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(X_en,Xfr_trunc)\n",
    "            labels = Y[:,N]\n",
    "            loss = loss_fn(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            # Bookkeeping\n",
    "            cost_hist[N].append((loss.item(),step))\n",
    "            if loss.item() > 0:\n",
    "                epoch_train_cost += loss.item()\n",
    "            step += 1\n",
    "            \n",
    "        epoch_train_cost /= len(dataloader)\n",
    "        run_train_hist.append(epoch_train_cost)\n",
    "        epoch_val_cost = give_cost_0(val_set, model, loss_fn)\n",
    "        val_hist.append(epoch_val_cost)\n",
    "        if epoch_val_cost < best_epoch[1]:\n",
    "            best_model = model\n",
    "            best_epoch = (n+1, epoch_val_cost)\n",
    "        if printing == True:\n",
    "            print(f'Epoch {n + 1}. Train cost: {epoch_train_cost}. Val cost: {epoch_val_cost}')    \n",
    "    end = time()\n",
    "    print(f'Best epoch: {best_epoch[0]}')\n",
    "    print(f'Time taken: {end - start} seconds')\n",
    "    \n",
    "    return cost_hist, run_train_hist, val_hist, best_model, best_epoch\n",
    "\n",
    "def run_tests(model,cost_hist, run_train_hist, val_hist):\n",
    "    plt.plot(run_train_hist, label = 'train')\n",
    "    plt.plot(val_hist, label = 'val')\n",
    "    plt.title('epoch training curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    model.to(device='cpu')\n",
    "    print('This is a sentence: ', model.translate('This is a sentence'))\n",
    "    print('another test: ', model.translate('another test'))\n",
    "    print('just one more: ', model.translate('just one more'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f32a5",
   "metadata": {
    "papermill": {
     "duration": 0.015168,
     "end_time": "2023-10-05T21:33:05.598755",
     "exception": false,
     "start_time": "2023-10-05T21:33:05.583587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fc78531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-05T21:33:05.633709Z",
     "iopub.status.busy": "2023-10-05T21:33:05.632775Z",
     "iopub.status.idle": "2023-10-06T01:20:36.385764Z",
     "shell.execute_reply": "2023-10-06T01:20:36.384759Z"
    },
    "papermill": {
     "duration": 13650.772642,
     "end_time": "2023-10-06T01:20:36.387803",
     "exception": false,
     "start_time": "2023-10-05T21:33:05.615161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation cost:  7.659948303854677\n",
      "Best epoch: 89\n",
      "Time taken: 13623.551284313202 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [00:22<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End validation costs:  [1.2098996408239624, 1.479899604292311, 1.7023527102004847, 1.7559742994562408, 1.3643361139579637, 0.9644898562389013, 0.30148190475301817, 0.02218202273821283]\n",
      "sum:  8.800616152461094\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence:  ceci est une phrase\n",
      "another test:  fais un autre problème\n",
      "just one more:  en simplement un simplement\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "n_epochs = 500 # Number of epochs\n",
    "batch_size = 64 # Batch size\n",
    "dropout = 0 # Dropout value\n",
    "lr = 0.01 # Learning rate\n",
    "printing = False # Print after each epoch? \n",
    "\n",
    "# Model parameters\n",
    "n_layers = 6 # Number of layers for encoder and decoder stacks\n",
    "nhead = 6 # Number of heads in multihead attention layers\n",
    "dim_feedforward = 1024 # Number of hidden neurons in positionwise-FCNN \n",
    "dim_out_hidden = 1024 # Number of hidden neurons in output FCNN\n",
    "\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TranslationSystem(fr_wordlst, N_in = 7, N_out = 8, emb_size = 300,\n",
    "                          n_layers = n_layers, nhead = nhead, dim_feedforward = dim_feedforward, \n",
    "                          dim_out_hidden = dim_out_hidden, dropout = dropout).to(device=device)\n",
    "optimiser = optim.SGD(model.parameters(), lr = lr)\n",
    "cost_hist, run_train_hist, val_hist, best_model, best_epoch  = train(model=model, optimiser = optimiser, n_epochs=n_epochs,\n",
    "                                                                    train_set = trainset, val_set = valset, batch_size=batch_size,\n",
    "                                                                    device = device, printing = printing)\n",
    "\n",
    "costs = give_cost_all(valset, model)\n",
    "print('End validation costs: ', costs)\n",
    "print('sum: ', sum(costs))\n",
    "\n",
    "run_tests(model,cost_hist, run_train_hist, val_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89282b0",
   "metadata": {
    "papermill": {
     "duration": 0.023896,
     "end_time": "2023-10-06T01:20:36.436097",
     "exception": false,
     "start_time": "2023-10-06T01:20:36.412201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that although there seems to be some overfitting here, I did not manage to improve the validation error with 0.01 dropout.\n",
    "\n",
    "The model with the best validation error during the training process was saved as `best_model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f5fe261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T01:20:36.482817Z",
     "iopub.status.busy": "2023-10-06T01:20:36.482464Z",
     "iopub.status.idle": "2023-10-06T01:20:37.286607Z",
     "shell.execute_reply": "2023-10-06T01:20:37.285639Z"
    },
    "papermill": {
     "duration": 0.830441,
     "end_time": "2023-10-06T01:20:37.289288",
     "exception": false,
     "start_time": "2023-10-06T01:20:36.458847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence:  ceci est une phrase\n",
      "another test:  fais un autre problème\n",
      "just one more:  en simplement un simplement\n",
      "the car is red:  la voiture est rouge\n",
      "the dog walks:  le chien marche\n"
     ]
    }
   ],
   "source": [
    "print('This is a sentence: ', best_model.translate('This is a sentence'))\n",
    "print('another test: ', best_model.translate('another test'))\n",
    "print('just one more: ', best_model.translate('just one more'))\n",
    "print('the car is red: ', best_model.translate('the car is red'))\n",
    "print('the dog walks: ', best_model.translate('the dog walks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "702e8650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T01:20:37.387311Z",
     "iopub.status.busy": "2023-10-06T01:20:37.386809Z",
     "iopub.status.idle": "2023-10-06T01:20:37.745872Z",
     "shell.execute_reply": "2023-10-06T01:20:37.744771Z"
    },
    "papermill": {
     "duration": 0.407691,
     "end_time": "2023-10-06T01:20:37.749218",
     "exception": false,
     "start_time": "2023-10-06T01:20:37.341527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model,'EnFrmodel_051023_0drop500epochs.pt')\n",
    "torch.save(best_model,'EnFrbestmodel_051023_0drop500epochs.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13752.703768,
   "end_time": "2023-10-06T01:20:41.107230",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-05T21:31:28.403462",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
