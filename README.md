# DL-notebooks

**English to French translation system with transformers II: Training.** An English-French translation model is constructed using an Encoder-Decoder Transformer stack and pre-trained fastText word Embeddings. The model is trained - approx. 3 hours on Kaggle T4 x2 GPUs.

**English to French translation system with transformers I: Data cleaning.** A raw English-French dataset is cleaned in preparation for training. Statistics such as word frequency are explored in order to support the later construction of the model. 

**Autoencoders: From linear to non-linear.** Visualising the principal components of MNIST. Training deep auto-encoders and comparing to PCA. Visualising paths between different images in the learned manifold. Creating a simple generative model. 

**Probabilistic neural networks and PAC-Bayes bounds.** Learning to train probabilistic neural networks and compute PAC-Bayes generalisation error bounds with a simple example. 

**Visualising CNNs.** Exploring convolutions for blur and edge detections. Training a CNN for MNIST and visualising the outputs of hidden neurons.

**Imbalanced data and ROC curves.** Exploring ROC curves and the AUC score for imbalanced datasets.

**Bias-Variance-Tradeoff.** Visualisations for understanding the bias-variance trade-off for classification models, using a 2D synthetic dataset. 

**XOR game.** A widget in which the user uses sliders to adjust the weights and biases of a neural network, aiming to exactly fit the XOR function.
